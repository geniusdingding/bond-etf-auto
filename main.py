import os
import io
import re
import pandas as pd
from datetime import datetime
import requests
import json

INPUT_DIR = "input"
OUTPUT_DIR = "output"
ETF_PATH = os.path.join("config", "ç§‘åˆ›å€ºåå•.xlsx")
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "ç§‘åˆ›å€ºETF_ç´¯è®¡ç»“æœ.xlsx")
WEBHOOK_URL = "ä½ çš„é£ä¹¦ webhook å¡«è¿™é‡Œ"  # âœ… ä¿®æ”¹ä¸ºä½ çš„çœŸå® webhook


def extract_date_from_filename(filename: str) -> str:
    """
    ä»æ–‡ä»¶åä¸­æå–8ä½æ•°å­—æ—¥æœŸï¼Œä¾‹å¦‚ 20251124 -> 2025/11/24
    """
    basename = os.path.basename(filename)
    m = re.search(r"(\d{8})", basename)
    if not m:
        raise ValueError(f"âŒ æ–‡ä»¶åä¸­æœªæ‰¾åˆ°æ—¥æœŸ: {basename}")

    date_str = m.group(1)
    return f"{date_str[0:4]}/{date_str[4:6]}/{date_str[6:8]}"


def load_all_input_files():
    """
    è·å– input ç›®å½•ä¸‹æ‰€æœ‰ Excel æ–‡ä»¶ï¼ŒæŒ‰æ–‡ä»¶åæ—¥æœŸæ’åºè¿”å›
    """
    files = [
        os.path.join(INPUT_DIR, f)
        for f in os.listdir(INPUT_DIR)
        if f.lower().endswith((".xls", ".xlsx"))
    ]

    if not files:
        raise FileNotFoundError("âŒ input ç›®å½•æ²¡æœ‰ä»»ä½• Excel æ–‡ä»¶ï¼Œè¯·å…ˆæ”¾å…¥æ–‡ä»¶")

    # æå–æ—¥æœŸå¹¶æ’åº
    sorted_files = sorted(files, key=lambda x: extract_date_from_filename(x))
    print("âœ… å°†æŒ‰ä»¥ä¸‹é¡ºåºå¤„ç†æ–‡ä»¶:")
    for f in sorted_files:
        print("   â†’", os.path.basename(f))

    return sorted_files


def load_or_init_result(df_template):
    """
    å¦‚æœå·²æœ‰ç´¯è®¡ç»“æœæ–‡ä»¶ï¼Œåˆ™è¯»å–ï¼›
    å¦åˆ™ç”¨ç§‘åˆ›å€ºåå•åˆå§‹åŒ–
    """
    if os.path.exists(OUTPUT_FILE):
        print(f"âœ… å·²æ‰¾åˆ°ç´¯è®¡ç»“æœï¼Œå°†åŠ è½½: {OUTPUT_FILE}")
        return pd.read_excel(OUTPUT_FILE)
    else:
        print("âœ… æœªæ‰¾åˆ°ç´¯è®¡ç»“æœï¼Œå°†æ–°å»ºæ–‡ä»¶")
        return df_template.copy()


def process_single_file(file_path, df_result):
    """
    å¤„ç†å•ä¸ª input æ–‡ä»¶å¹¶æ›´æ–°ç´¯è®¡ç»“æœ
    """
    date_col = extract_date_from_filename(file_path)
    print(f"âœ… å¼€å§‹å¤„ç† {os.path.basename(file_path)} â†’ æ—¥æœŸåˆ—: {date_col}")

    with open(file_path, "rb") as f:
        file_stream = io.BytesIO(f.read())

    try:
        df_sh = pd.read_excel(file_stream, header=2)
    except:
        df_sh = pd.read_csv(file_stream, header=2, sep=None, engine="python")

    col_code = df_sh.columns[0]
    col_rate = df_sh.columns[2]

    df_sh = df_sh.dropna(subset=[col_code])
    df_sh[col_code] = pd.to_numeric(df_sh[col_code], errors="coerce").astype("Int64")
    df_result["åŸºé‡‘ä»£ç "] = pd.to_numeric(df_result["åŸºé‡‘ä»£ç "], errors="coerce").astype("Int64")

    rate_map = dict(zip(df_sh[col_code], df_sh[col_rate]))
    df_result[date_col] = df_result["åŸºé‡‘ä»£ç "].map(rate_map)

    return df_result


def sort_columns(df):
    fixed_cols = ["åŸºé‡‘ä»£ç ", "åŸºé‡‘ç®€ç§°"]
    date_cols = sorted([c for c in df.columns if c not in fixed_cols])
    return df[fixed_cols + date_cols]


def send_to_feishu(file_name, summary_text=None):
    date = datetime.now().strftime("%Y-%m-%d")
    raw_url = f"https://raw.githubusercontent.com/geniusdingding/bond-etf-auto/main/output/{file_name}"

    data = {
        "msg_type": "post",
        "content": {
            "post": {
                "zh_cn": {
                    "title": "ç§‘åˆ›å€ºæŠ˜ç®—ç‡æ›´æ–°",
                    "content": [
                        [
                            {"tag": "text", "text": summary_text or "âœ… ç§‘åˆ›å€ºæŠ˜ç®—ç‡å·²æ›´æ–°"}
                        ],
                        [
                            {"tag": "a", "text": "ğŸ“ ç‚¹å‡»ä¸‹è½½æœ€æ–°æ–‡ä»¶", "href": raw_url}
                        ]
                    ]
                }
            }
        }
    }

    headers = {"Content-Type": "application/json"}
    try:
        resp = requests.post(WEBHOOK_URL, data=json.dumps(data), headers=headers)
        print("âœ… é£ä¹¦æ¨é€æˆåŠŸ:", resp.text)
    except Exception as e:
        print("âŒ é£ä¹¦æ¨é€å¤±è´¥:", e)



if __name__ == "__main__":
    # è¯»å–ETFåå•
    df_template = pd.read_excel(ETF_PATH)
    df_template = df_template[["åŸºé‡‘ä»£ç ", "åŸºé‡‘ç®€ç§°"]]

    # åˆå§‹åŒ–æˆ–è¯»å–ç´¯è®¡æ–‡ä»¶
    df_result = load_or_init_result(df_template)

    # ä¾æ¬¡å¤„ç†æ‰€æœ‰ input æ–‡ä»¶
    files = load_all_input_files()
    for f in files:
        df_result = process_single_file(f, df_result)

    # æ’åºåˆ—
    df_result = sort_columns(df_result)

    # ä¿å­˜è¾“å‡º
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    df_result.to_excel(OUTPUT_FILE, index=False)

    print(f"âœ… å·²ç”Ÿæˆæ–‡ä»¶ â†’ {OUTPUT_FILE}")

    # âœ… æ–°å¢â€”â€”ç”Ÿæˆå½“æœŸæ•°æ® summary å¹¶æ¨é€

    # âœ… è®¡ç®—æœ€æ–°æ—¥æœŸåˆ—
    date_cols = [c for c in df_result.columns if c not in ["åŸºé‡‘ä»£ç ", "åŸºé‡‘ç®€ç§°"]]
    latest_col = sorted(date_cols)[-1]

    # âœ… è¿‡æ»¤æ‰æ— æ•°æ®çš„åŸºé‡‘
    valid_series = df_result[latest_col].dropna()
    count = len(valid_series)

    # âœ… è®¡ç®—å¹³å‡æŠ˜ç®—ç‡
    avg_rate = round(valid_series.mean(), 2)

    # âœ… ç”Ÿæˆ summary æ–‡æœ¬
    summary = f"âœ… {latest_col} ç§‘åˆ›å€ºæŠ˜ç®—ç‡æ›´æ–°\nå…±æœ‰ {count} åªç§‘åˆ›å€ºETFå¯è´¨æŠ¼\nå¹³å‡æŠ˜ç®—ç‡ä¸º {avg_rate}%"

    # âœ… é£ä¹¦æ¨é€ summary
    send_to_feishu("ç§‘åˆ›å€ºETF_ç´¯è®¡ç»“æœ.xlsx", summary)
    send_to_feishu("ç§‘åˆ›å€ºETF_ç´¯è®¡ç»“æœ.xlsx")

    # âœ… GitHub Actions è‡ªåŠ¨æäº¤
    os.system(f"git add {OUTPUT_FILE}")
    os.system('git commit -m "update result" || echo "no changes"')

    print(f"\nğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼ç´¯è®¡ç»“æœå·²æ›´æ–° â†’ {OUTPUT_FILE}\n")
